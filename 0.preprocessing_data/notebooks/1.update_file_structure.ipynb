{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy raw images into one folder to use for CellProfiler processing\n",
    "\n",
    "Currently, the images are located nest deep within multiple folders. \n",
    "For best practices, we will copy the images (preserving metadata) to one folder that can be used for CellProfiler processing.\n",
    "This file is modified from its original version: https://github.com/WayScience/GFF_2D_organoid_prototyping ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import sys\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "\n",
    "sys.path.append(str(root_dir / \"utils\"))\n",
    "from notebook_init_utils import avoid_path_crash_bandicoot, init_notebook\n",
    "\n",
    "root_dir, in_notebook = init_notebook()\n",
    "\n",
    "if in_notebook:\n",
    "    import tqdm.notebook as tqdm\n",
    "else:\n",
    "    import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argparse = argparse.ArgumentParser(\n",
    "    description=\"Copy files from one directory to another\"\n",
    ")\n",
    "argparse.add_argument(\"--HPC\", action=\"store_true\", help=\"Type of compute to run on\")\n",
    "# Parse arguments\n",
    "args = argparse.parse_args(args=sys.argv[1:] if \"ipykernel\" not in sys.argv[0] else [])\n",
    "HPC = args.HPC\n",
    "\n",
    "print(f\"HPC: {HPC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if bandicoot is set\n",
    "# check if bandicoot is set\n",
    "bandicoot_path = pathlib.Path(os.path.expanduser(\"~/mnt/bandicoot\")).resolve()\n",
    "if not HPC and bandicoot_path.exists():\n",
    "    bandicoot = True\n",
    "else:\n",
    "    bandicoot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HPC:\n",
    "    raw_image_dir = pathlib.Path(\"/pl/active/koala/GFF_Data/GFF-Raw/\").resolve(\n",
    "        strict=True\n",
    "    )\n",
    "    output_base_dir = root_dir\n",
    "elif bandicoot:\n",
    "    # comment out depending on whose computer you are on\n",
    "    # mike's computer\n",
    "    bandicoot_path = pathlib.Path(\n",
    "        os.path.expanduser(\"~/mnt/bandicoot/NF1_organoid_data\")\n",
    "    ).resolve(strict=True)\n",
    "    # Jenna's computer\n",
    "    # bandicoot_path = pathlib.Path(\"/media/18tbdrive/GFF_organoid_data/\")\n",
    "    raw_image_dir = pathlib.Path(f\"{bandicoot_path}/Raw_patient_files\").resolve(\n",
    "        strict=True\n",
    "    )\n",
    "    output_base_dir = bandicoot_path\n",
    "else:\n",
    "    # comment out depending on whose computer you are on\n",
    "    # mike's computer\n",
    "    raw_image_dir = pathlib.Path(\"~/Desktop/20TB_A/NF1_Patient_organoids\").resolve(\n",
    "        strict=True\n",
    "    )\n",
    "    # Jenna's computer\n",
    "    # raw_image_dir_local = pathlib.Path(\"/media/18tbdrive/GFF_organoid_data/\")\n",
    "    output_base_dir = root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base_dir = root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parent and destination directories in a single dictionary\n",
    "dir_mapping = {\n",
    "    \"NF0014_T1\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/NF0014-Thawed 3 (Raw image files)-Combined/NF0014-Thawed 3 (Raw image files)-Combined copy\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0014_T1/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"NF0014_T2\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/NF0014-T2 Cell Painting/NF0014-T2 Combined/\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0014_T2/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"NF0016_T1\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/NF0016 Cell Painting-Pilot Drug Screening-selected/NF0016-Cell Painting Images/NF0016-images copy\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0016_T1/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"NF0017\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/NF0017-T3-P7 (AGP, Mito Parameter optimization)/Acquisition 03-07-2025\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0017/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"NF0018_T6\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/NF0018 (T6) Cell Painting-Pilot Drug Screeining/NF0018-Cell Painting Images/NF0018-All Acquisitions\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0018_T6/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"NF0021_T1\": {\n",
    "        \"parent\": pathlib.Path(f\"{raw_image_dir}/NF0021-T1/NF0021-T1 Combined\").resolve(\n",
    "            strict=True\n",
    "        ),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0021_T1/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"NF0030_T1\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/NF0030 Cell Painting/NF0030 Cell Painting/NF0030-Cell Painting Images/Combined\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0030_T1/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"NF0040_T1\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/SARC0376 (NF0040) Cell Painting/SARC0376 (NF0040) Cell Painting/SARC0376 (NF0040)-Cell Painting Images/Combined\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/NF0040_T1/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"SACRO219_T1\": {\n",
    "        \"parent\": pathlib.Path(\n",
    "            f\"{raw_image_dir}/SARC0219-T2 Cell Painting-selected/SARC0219-T2 Combined Cell Painting images/SARC0219-T2 Combined/\"\n",
    "        ).resolve(strict=True),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/SARCO219_T1/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"SARCO361_T1\": {\n",
    "        \"parent\": pathlib.Path(f\"{raw_image_dir}/SARC0361/SARC0361 Combined/\").resolve(\n",
    "            strict=True\n",
    "        ),\n",
    "        \"destination\": pathlib.Path(\n",
    "            f\"{output_base_dir}/data/SARCO361_T1/raw_images\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Image extensions that we are looking to copy\n",
    "image_extensions = {\".tif\", \".tiff\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reach the nested images and copy to one folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set QC functions that determine if a well/site is of good quality to process based on file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_consistent_naming(well_dir: pathlib.Path) -> bool:\n",
    "    \"\"\"Check that all nested folders within a well directory have the same names as the well directory itself.\n",
    "\n",
    "    Args:\n",
    "        well_dir (pathlib.Path): Path to a single well directory.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all nested folders inside this well directory have the same name as the well directory, False otherwise.\n",
    "    \"\"\"\n",
    "    # Get the name of the well directory (this will be the expected folder name)\n",
    "    well_name = well_dir.name\n",
    "\n",
    "    # Get the immediate subdirectories in the well directory (e.g., Field_1, Field_2)\n",
    "    sub_dirs = [d for d in well_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "    if not sub_dirs:\n",
    "        return False  # No nested folders found, treat as inconsistent\n",
    "\n",
    "    # Check if each subdirectory contains a nested folder with the same name as the well directory\n",
    "    for sub in sub_dirs:\n",
    "        nested_folders = [d.name for d in sub.iterdir() if d.is_dir()]\n",
    "        if well_name not in nested_folders:\n",
    "            return False  # Inconsistent folder structure found\n",
    "\n",
    "    return True  # All subdirectories have a nested folder with the same name as the well directory\n",
    "\n",
    "\n",
    "def is_image_folder_empty(nested_dir: pathlib.Path) -> bool:\n",
    "    \"\"\"Check if a nested directory contains any images.\n",
    "\n",
    "    Args:\n",
    "        nested_dir (pathlib.Path): Path to a directory nested within the well directory\n",
    "\n",
    "    Returns:\n",
    "        bool: Boolean indicating whether the nested directory contains any images\n",
    "    \"\"\"\n",
    "    return not any(\n",
    "        image.suffix.lower() in image_extensions for image in nested_dir.rglob(\"*\")\n",
    "    )\n",
    "\n",
    "\n",
    "def has_equal_images_per_channel(\n",
    "    nested_dir: pathlib.Path, channel_names: list[str]\n",
    ") -> bool:\n",
    "    \"\"\"Check if all specified channels have the same number of images by looking for the channel name in the filenames.\n",
    "\n",
    "    Args:\n",
    "        nested_dir (pathlib.Path): Path to a directory nested within the well directory.\n",
    "        channel_names (list[str]): List of strings of the channel names found in the nested directory.\n",
    "\n",
    "    Returns:\n",
    "        bool: Boolean indicating whether all specified channels have the same number of images.\n",
    "    \"\"\"\n",
    "    # Initialize counts for each channel\n",
    "    channel_counts = {channel: 0 for channel in channel_names}\n",
    "\n",
    "    # Count images for each channel based on the channel name in the filename\n",
    "    for image in nested_dir.rglob(\"*\"):  # Search for all files recursively\n",
    "        if image.suffix.lower() in image_extensions:  # Ensure it's an image file\n",
    "            for channel in channel_names:\n",
    "                if (\n",
    "                    channel in image.name\n",
    "                ):  # If the channel name is found in the image filename\n",
    "                    channel_counts[channel] += 1\n",
    "\n",
    "    # Get the unique set of image counts (if all counts are equal, there should be only one unique value)\n",
    "    image_counts = set(channel_counts.values())\n",
    "\n",
    "    # If all counts are equal and non-zero, return True; otherwise, return False\n",
    "    return len(image_counts) == 1 and 0 not in image_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell through the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single nested directory\n",
    "\n",
    "\n",
    "def process_nested_dir(nested_dir, dest_well_dir, channel_names, image_extensions):\n",
    "    if not nested_dir.is_dir():\n",
    "        return f\"Skipping {nested_dir}: Not a directory\"\n",
    "\n",
    "    if is_image_folder_empty(nested_dir):\n",
    "        return f\"Skipping {nested_dir}: No images found\"\n",
    "\n",
    "    if not has_equal_images_per_channel(nested_dir, channel_names):\n",
    "        return f\"Skipping {nested_dir}: Unequal images per channel\"\n",
    "\n",
    "    # Copy images to destination, skipping files with 'Tile' in their name\n",
    "    for image in nested_dir.rglob(\"*\"):\n",
    "        if image.suffix.lower() in image_extensions and \"Tile\" not in image.name:\n",
    "            shutil.copy2(image, dest_well_dir)\n",
    "\n",
    "    return f\"Processed {nested_dir}\"\n",
    "\n",
    "\n",
    "# Function to process a single well directory\n",
    "def process_well_dir(well_dir, dest_dir, channel_names, image_extensions):\n",
    "    if not has_consistent_naming(well_dir):\n",
    "        return f\"Skipping {well_dir.stem}: Inconsistent nested folder names within well\"\n",
    "\n",
    "    dest_well_dir = dest_dir / well_dir.name\n",
    "    dest_well_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    nested_dirs = list(well_dir.iterdir())\n",
    "    for nested_dir in nested_dirs:\n",
    "        process_nested_dir(\n",
    "            nested_dir,\n",
    "            dest_well_dir,\n",
    "            channel_names,\n",
    "            image_extensions,\n",
    "        )\n",
    "\n",
    "\n",
    "# Set channel names\n",
    "channel_names = {\"405\", \"488\", \"555\", \"640\", \"TRANS\", \"Merge\"}\n",
    "\n",
    "# Loop through each key in the mapping to copy data from the parent to the destination\n",
    "for key, paths in dir_mapping.items():\n",
    "    parent_dir = paths[\"parent\"]\n",
    "    dest_dir = paths[\"destination\"]\n",
    "\n",
    "    print(f\"Processing {key}: {parent_dir} -> {dest_dir}\")\n",
    "\n",
    "    # Ensure the destination directory exists\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all well-level directories\n",
    "    well_dirs = [d for d in parent_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "    if not well_dirs:\n",
    "        print(f\"Skipping {key}: No well directories found\")\n",
    "        continue\n",
    "    # Process well directories in parallel\n",
    "    with ProcessPoolExecutor(max_workers=multiprocessing.cpu_count() - 2) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_well_dir, well_dir, dest_dir, channel_names, image_extensions\n",
    "            )\n",
    "            for well_dir in well_dirs\n",
    "        ]\n",
    "        for future in tqdm.tqdm(\n",
    "            as_completed(futures),\n",
    "            desc=f\"Processing {key}\",\n",
    "            leave=False,\n",
    "            total=len(well_dirs),\n",
    "        ):\n",
    "            pass\n",
    "\n",
    "    print(f\"Completed processing {key}: {parent_dir} -> {dest_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NF0016 specific preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir_NF0016 = pathlib.Path(\n",
    "    f\"{output_base_dir}/data/NF0016_T1/raw_images\"\n",
    ").resolve(strict=True)\n",
    "# get all dirs in the parent dir\n",
    "parent_dir_NF0016 = list(parent_dir_NF0016.glob(\"*/\"))\n",
    "parent_dir_NF0016 = [x for x in parent_dir_NF0016 if x.is_dir()]\n",
    "# get all child files in the parent dir\n",
    "file_dir_NF0016 = []\n",
    "for parent_dir in parent_dir_NF0016:\n",
    "    file_dir_NF0016.extend(list(parent_dir.glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the files in the parent dir\n",
    "for file in file_dir_NF0016:\n",
    "    new_file_dir = pathlib.Path(\n",
    "        f\"{file.parent}/{str(file.stem).replace(' (60X)', '')}.{file.suffix}\"\n",
    "    )\n",
    "    file.rename(new_file_dir)\n",
    "\n",
    "# rename the parent dir\n",
    "for parent_dir in parent_dir_NF0016:\n",
    "    new_parent_dir = pathlib.Path(\n",
    "        f\"{parent_dir.parent}/{str(parent_dir.stem).replace(' (60X)', '')}\"\n",
    "    )\n",
    "    # rename the parent dir\n",
    "    os.rename(parent_dir, new_parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NF0018 specific preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir_NF0018 = pathlib.Path(\n",
    "    f\"{output_base_dir}/data/NF0018_T6/raw_images\"\n",
    ").resolve(strict=True)\n",
    "# get all dirs in the parent dir\n",
    "parent_dir_NF0018 = list(parent_dir_NF0018.glob(\"*/\"))\n",
    "parent_dir_NF0018 = [x for x in parent_dir_NF0018 if x.is_dir()]\n",
    "# get all child files in the parent dir\n",
    "file_dir_NF0018 = []\n",
    "for parent_dir in parent_dir_NF0018:\n",
    "    file_dir_NF0018.extend(list(parent_dir.glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the files in the parent dir\n",
    "for file in file_dir_NF0018:\n",
    "    new_file_dir = pathlib.Path(\n",
    "        f\"{file.parent}/{str(file.stem).replace(' (60X)', '')}{file.suffix}\"\n",
    "    )\n",
    "    file.rename(new_file_dir)\n",
    "\n",
    "# rename the parent dir\n",
    "for parent_dir in parent_dir_NF0018:\n",
    "    new_parent_dir = pathlib.Path(\n",
    "        f\"{parent_dir.parent}/{str(parent_dir.stem).replace(' (60X)', '')}\"\n",
    "    )\n",
    "    # rename the parent dir\n",
    "    os.rename(parent_dir, new_parent_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gff_preprocessing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
