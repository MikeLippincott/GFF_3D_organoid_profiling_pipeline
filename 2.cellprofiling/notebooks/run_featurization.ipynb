{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pathlib\n",
                "import sys\n",
                "import time\n",
                "\n",
                "sys.path.append(\"../featurization\")\n",
                "from area_size_shape import measure_3D_area_size_shape\n",
                "from colocalization import (\n",
                "    measure_3D_colocalization,\n",
                "    prepare_two_images_for_colocalization,\n",
                ")\n",
                "from granularity import measure_3D_granularity\n",
                "from intensity import measure_3D_intensity\n",
                "from loading_classes import ImageSetLoader, ObjectLoader, TwoObjectLoader\n",
                "from neighbors import measure_3D_number_of_neighbors\n",
                "from texture import measure_3D_texture\n",
                "\n",
                "try:\n",
                "    cfg = get_ipython().config\n",
                "    in_notebook = True\n",
                "except NameError:\n",
                "    in_notebook = False\n",
                "if in_notebook:\n",
                "    from tqdm.notebook import tqdm\n",
                "else:\n",
                "    from tqdm import tqdm\n",
                "\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
                "import gc\n",
                "import itertools\n",
                "\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# begin profiling timer\n",
                "start = time.time()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Set the path to the images "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "image_set_path = pathlib.Path(\"../../data/NF0014/cellprofiler/C4-2/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### set the channel mapping dictionary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "channel_mapping = {\n",
                "    \"DNA\": \"405\",\n",
                "    \"AGP\": \"488\",\n",
                "    \"ER\": \"555\",\n",
                "    \"Mito\": \"640\",\n",
                "    \"BF\": \"TRANS\",\n",
                "    \"Nuclei\": \"nuclei_\",\n",
                "    \"Cell\": \"cell_\",\n",
                "    \"Cytoplasm\": \"cytoplasm_\",\n",
                "    \"Organoid\": \"organoid_\",\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Initialize the image set loader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "image_set_loader = ImageSetLoader(\n",
                "    image_set_path=image_set_path,\n",
                "    spacing=(1, 0.1, 0.1),\n",
                "    channel_mapping=channel_mapping,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Loop through the image set"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Run the rest in a script as it takes a long time to run"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "texture = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2570de32eb8a444eb1a4a1f8b10c93f0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Processing compartments:   0%|          | 0/4 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "83493b3513ab402d9eeb5c0d42c10e58",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Processing channels:   0%|          | 0/9 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loading object loader\n",
                        "area size shape\n",
                        "granularity\n"
                    ]
                }
            ],
            "source": [
                "for compartment in tqdm(\n",
                "    image_set_loader.compartments, desc=\"Processing compartments\", position=0\n",
                "):\n",
                "    for channel in tqdm(\n",
                "        image_set_loader.image_names,\n",
                "        desc=\"Processing channels\",\n",
                "        leave=False,\n",
                "        position=1,\n",
                "    ):\n",
                "        # compartment = \"Organoid\"\n",
                "        # channel = \"AGP\"\n",
                "        print(\"loading object loader\")\n",
                "        object_loader = ObjectLoader(\n",
                "            image_set_loader.image_set_dict[channel],\n",
                "            image_set_loader.image_set_dict[compartment],\n",
                "            channel,\n",
                "            compartment,\n",
                "        )\n",
                "        print(\"area size shape\")\n",
                "        # area, size, shape\n",
                "        size_shape_dict = measure_3D_area_size_shape(\n",
                "            image_set_loader=image_set_loader,\n",
                "            object_loader=object_loader,\n",
                "        )\n",
                "        print(\"granularity\")\n",
                "        # granularity\n",
                "        object_measurements = measure_3D_granularity(\n",
                "            object_loader,\n",
                "            radius=10,\n",
                "            granular_spectrum_length=16,\n",
                "            subsample_size=0.25,\n",
                "            image_name=channel,\n",
                "        )\n",
                "        print(\"intensity\")\n",
                "        # intensity\n",
                "        output_dict = measure_3D_intensity(object_loader)\n",
                "        print(\"neighbors\")\n",
                "        # neighbors\n",
                "        neighbors_out_dict = measure_3D_number_of_neighbors(\n",
                "            object_loader=object_loader,\n",
                "            distance_threshold=10,\n",
                "            anisotropy_factor=image_set_loader.anisotropy_factor,\n",
                "        )\n",
                "        if texture:\n",
                "            output_texture_dict = measure_3D_texture(\n",
                "                object_loader=object_loader,\n",
                "                distance=1,\n",
                "            )\n",
                "        print(\"merging\")\n",
                "        # merge the dataframes together\n",
                "        size_shape_df = pd.DataFrame(size_shape_dict)\n",
                "        # prepend the feature_type to the column names\n",
                "        size_shape_df.columns = [\"object_id\"] + [\n",
                "            \"AreaSizeShape_\" + col\n",
                "            for col in size_shape_df.columns\n",
                "            if col != \"object_id\"\n",
                "        ]\n",
                "        granularity_df = pd.DataFrame(object_measurements)\n",
                "        # pivot wide\n",
                "        granularity_df = granularity_df.pivot(\n",
                "            index=\"object_id\", columns=\"feature\", values=\"value\"\n",
                "        )\n",
                "        granularity_df.reset_index(inplace=True)\n",
                "        # prepend the feature_type to the column names\n",
                "        granularity_df.columns = [\"object_id\"] + [\n",
                "            \"Granularity_\" + col for col in granularity_df.columns if col != \"object_id\"\n",
                "        ]\n",
                "        intensity_df = pd.DataFrame(output_dict)\n",
                "        # pivot wide\n",
                "        intensity_df = intensity_df.pivot(\n",
                "            index=\"object_id\", columns=\"feature_name\", values=\"value\"\n",
                "        )\n",
                "        intensity_df.reset_index(inplace=True)\n",
                "        # prepend the feature_type to the column names\n",
                "        intensity_df.columns = [\"object_id\"] + [\n",
                "            \"Intensity_\" + col for col in intensity_df.columns if col != \"object_id\"\n",
                "        ]\n",
                "        neighbors_df = pd.DataFrame(neighbors_out_dict)\n",
                "        # prepend the feature_type to the column names\n",
                "        neighbors_df.columns = [\"object_id\"] + [\n",
                "            \"Neighbors_\" + col for col in neighbors_df.columns if col != \"object_id\"\n",
                "        ]\n",
                "        final_df = pd.merge(\n",
                "            size_shape_df, granularity_df, left_on=\"object_id\", right_on=\"object_id\"\n",
                "        )\n",
                "        final_df = pd.merge(\n",
                "            final_df, intensity_df, left_on=\"object_id\", right_on=\"object_id\"\n",
                "        )\n",
                "        final_df = pd.merge(\n",
                "            final_df, neighbors_df, left_on=\"object_id\", right_on=\"object_id\"\n",
                "        )\n",
                "        # prepend compartment and channel to column names\n",
                "        final_df.columns = [\n",
                "            f\"{compartment}_{channel}_{col}\" for col in final_df.columns\n",
                "        ]\n",
                "        final_df[\"image_set\"] = image_set_loader.image_set_name\n",
                "        print(final_df.shape)\n",
                "        output_file = pathlib.Path(\n",
                "            f\"../results/{image_set_loader.image_set_name}_{compartment}_features.parquet\"\n",
                "        )\n",
                "        output_file.parent.mkdir(parents=True, exist_ok=True)\n",
                "        final_df.to_parquet(output_file)\n",
                "\n",
                "        # remove the objects initialized in the beginning of the loop\n",
                "        del object_loader\n",
                "        del size_shape_dict\n",
                "        del object_measurements\n",
                "        del output_dict\n",
                "        del neighbors_out_dict\n",
                "        if texture:\n",
                "            del output_texture_dict\n",
                "        del final_df\n",
                "        gc.collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Colocalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get all channel combinations\n",
                "channel_combinations = list(itertools.combinations(image_set_loader.image_names, 2))\n",
                "output_list_of_dfs = []\n",
                "for compartment in tqdm(\n",
                "    image_set_loader.compartments, desc=\"Processing compartments\", position=0\n",
                "):\n",
                "    for channel1, channel2 in tqdm(\n",
                "        channel_combinations,\n",
                "        desc=\"Processing channel combinations\",\n",
                "        leave=False,\n",
                "        position=1,\n",
                "    ):\n",
                "        # compartment = \"Organoid\"\n",
                "        # channel1 = \"AGP\"\n",
                "        # channel2 = \"ER\"\n",
                "\n",
                "        coloc_loader = TwoObjectLoader(\n",
                "            image_set_loader=image_set_loader,\n",
                "            compartment=compartment,\n",
                "            channel1=channel1,\n",
                "            channel2=channel2,\n",
                "        )\n",
                "        for object_id in tqdm(\n",
                "            coloc_loader.object_ids,\n",
                "            desc=\"Processing object IDs\",\n",
                "            leave=False,\n",
                "            position=2,\n",
                "        ):\n",
                "            cropped_image1, cropped_image2 = prepare_two_images_for_colocalization(\n",
                "                label_object1=coloc_loader.label_image,\n",
                "                label_object2=coloc_loader.label_image,\n",
                "                image_object1=coloc_loader.image1,\n",
                "                image_object2=coloc_loader.image2,\n",
                "                object_id1=object_id,\n",
                "                object_id2=object_id,\n",
                "            )\n",
                "            colocalization_features = measure_3D_colocalization(\n",
                "                cropped_image_1=cropped_image1,\n",
                "                cropped_image_2=cropped_image2,\n",
                "                thr=15,\n",
                "                fast_costes=\"Accurate\",\n",
                "            )\n",
                "            coloc_df = pd.DataFrame(colocalization_features, index=[0])\n",
                "            coloc_df[\"object_id\"] = object_id\n",
                "            # prepend compartment channel1 and channel2 to column names + colocalization\n",
                "            coloc_df.columns = [\n",
                "                f\"{compartment}_{channel1}_{channel2}_Colocalization_\" + col\n",
                "                for col in coloc_df.columns\n",
                "                if col != \"object_id\"\n",
                "            ] + [\"object_id\"]\n",
                "            output_list_of_dfs.append(coloc_df)\n",
                "        coloc_df = pd.concat(output_list_of_dfs)\n",
                "        coloc_df[\"image_set\"] = image_set_loader.image_set_name\n",
                "        print(coloc_df.shape)\n",
                "        output_file = pathlib.Path(\n",
                "            f\"../results/{image_set_loader.image_set_name}_{compartment}_coloc_features.parquet\"\n",
                "        )\n",
                "        output_file.parent.mkdir(parents=True, exist_ok=True)\n",
                "        final_df.to_parquet(output_file)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "end = time.time()\n",
                "print(f\"Time taken for {image_set_loader.image_set_name} featurization:\", end - start)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "GFF_featurization",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
