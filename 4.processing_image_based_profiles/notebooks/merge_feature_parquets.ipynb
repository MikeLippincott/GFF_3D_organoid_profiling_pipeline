{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import pathlib\n",
                "import pprint\n",
                "import sqlite3\n",
                "from contextlib import closing\n",
                "\n",
                "import duckdb\n",
                "import pandas as pd\n",
                "\n",
                "try:\n",
                "    cfg = get_ipython().config\n",
                "    in_notebook = True\n",
                "except NameError:\n",
                "    in_notebook = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not in_notebook:\n",
                "    argparser = argparse.ArgumentParser()\n",
                "    argparser.add_argument(\n",
                "        \"--well_fov\",\n",
                "        type=str,\n",
                "        required=True,\n",
                "        help=\"Well and field of view to process, e.g. 'A01_1'\",\n",
                "    )\n",
                "    argparser.add_argument(\n",
                "        \"--patient\",\n",
                "        type=str,\n",
                "        required=True,\n",
                "        help=\"Patient ID to process, e.g. 'P01'\",\n",
                "    )\n",
                "    args = argparser.parse_args()\n",
                "    well_fov = args.well_fov\n",
                "    patient = args.patient\n",
                "else:\n",
                "    well_fov = \"C4-2\"\n",
                "    patient = \"NF0014\"\n",
                "\n",
                "\n",
                "result_path = pathlib.Path(\n",
                "    f\"../../data/{patient}/extracted_features/{well_fov}\"\n",
                ").resolve(strict=True)\n",
                "database_path = pathlib.Path(f\"../../data/{patient}/converted_profiles/\").resolve()\n",
                "database_path.mkdir(parents=True, exist_ok=True)\n",
                "# create the sqlite database\n",
                "sqlite_path = database_path / f\"{well_fov}.sqlite\"\n",
                "\n",
                "\n",
                "# get a list of all parquets in the directory\n",
                "parquet_files = list(result_path.glob(\"*.parquet\"))\n",
                "parquet_files.sort()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_types_dict = {\n",
                "    \"Organoid\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "    \"Cell\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "    \"Nuclei\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "    \"Cytoplasm\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "}\n",
                "for file in parquet_files:\n",
                "    for compartment in feature_types_dict.keys():\n",
                "        for feature_type in feature_types_dict[compartment].keys():\n",
                "            if compartment in file.name and feature_type in file.name:\n",
                "                feature_types_dict[compartment][feature_type].append(file)\n",
                "pprint.pprint(feature_types_dict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a record for each compartment\n",
                "merged_df_dict = {\n",
                "    \"Organoid\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "    \"Cell\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "    \"Nuclei\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "    \"Cytoplasm\": {\n",
                "        \"AreaSize_Shape\": [],\n",
                "        \"Colocalization\": [],\n",
                "        \"Intensity\": [],\n",
                "        \"Granularity\": [],\n",
                "        \"Neighbor\": [],\n",
                "        \"Texture\": [],\n",
                "    },\n",
                "}\n",
                "\n",
                "for compartment in feature_types_dict.keys():\n",
                "    for feature_type in feature_types_dict[compartment].keys():\n",
                "        if len(feature_types_dict[compartment][feature_type]) > 0:\n",
                "            for file in feature_types_dict[compartment][feature_type]:\n",
                "                # check if the file exists\n",
                "                if not file.exists():\n",
                "                    print(f\"File {file} does not exist\")\n",
                "                    continue\n",
                "                # check if the file is a parquet file\n",
                "                if not file.name.endswith(\".parquet\"):\n",
                "                    print(f\"File {file} is not a parquet file\")\n",
                "                    continue\n",
                "                # read the parquet files\n",
                "                try:\n",
                "                    df = duckdb.read_parquet(str(file)).to_df()\n",
                "                except Exception as e:\n",
                "                    print(\n",
                "                        f\"Error reading {feature_types_dict[compartment][feature_type]}: {e}\"\n",
                "                    )\n",
                "                    df = pd.DataFrame()\n",
                "\n",
                "                # add the dataframe to the dictionary\n",
                "                merged_df_dict[compartment][feature_type].append(df)\n",
                "        else:\n",
                "            print(\n",
                "                f\"No files found for {compartment} {feature_type}. Please check the directory.\"\n",
                "            )\n",
                "            merged_df_dict[compartment][feature_type].append(pd.DataFrame())\n",
                "        # merge the dataframes\n",
                "        merged_df_dict[compartment][feature_type] = pd.concat(\n",
                "            merged_df_dict[compartment][feature_type], ignore_index=True\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with closing(sqlite3.connect(sqlite_path)) as cx:\n",
                "    # with cx:\n",
                "    # conn = sqlite3.connect(sqlite_path)\n",
                "    # merge all the feature types into one dataframe\n",
                "    for compartment in merged_df_dict.keys():\n",
                "        merged_df = pd.DataFrame(\n",
                "            {\n",
                "                \"object_id\": [],\n",
                "                \"image_set\": [],\n",
                "            }\n",
                "        )\n",
                "        for feature_type, feature_type_df in merged_df_dict[compartment].items():\n",
                "            if len(feature_type_df) > 0:\n",
                "                merged_df = pd.merge(\n",
                "                    merged_df,\n",
                "                    feature_type_df,\n",
                "                    on=[\"object_id\", \"image_set\"],\n",
                "                    how=\"outer\",\n",
                "                )\n",
                "            else:\n",
                "                print(f\"Dataframe {feature_type} is empty\")\n",
                "                continue\n",
                "\n",
                "        merged_df.to_sql(\n",
                "            f\"{compartment}\",\n",
                "            cx,\n",
                "            if_exists=\"replace\",\n",
                "            index=False,\n",
                "        )"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nf1_image_based_profiling_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
