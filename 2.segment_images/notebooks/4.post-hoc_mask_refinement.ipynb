{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Segmentation corrections"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The goal of this notebook is to correct potential errors in the segmentation of the 3D image data.\n",
                "Potential errors can be observed in the figure below where each row is a different slice of the 3D image data and each column is a different outcome of the segmentation.\n",
                "Each segmentation of cell and nucleus is shown in a different color.\n",
                "Where cells or nuclei that are the same object id are shown in the same color.\n",
                "While cells and nuclei that are different object ids are shown in different colors.\n",
                "Some of the outcomes are not correct and need to be corrected.\n",
                "While others might be correct or incorrect but there is not logical way to determine if they are correct or not. \n",
                "These cases are not corrected.\n",
                "![Segmentation errors](../media/3D_segmentations_correction_events.png)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import pathlib\n",
                "import sys\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import skimage\n",
                "import tifffile\n",
                "\n",
                "sys.path.append(\"../../utils\")\n",
                "\n",
                "from segmentation_decoupling import euclidian_2D_distance\n",
                "\n",
                "# check if in a jupyter notebook\n",
                "try:\n",
                "    cfg = get_ipython().config\n",
                "    in_notebook = True\n",
                "except NameError:\n",
                "    in_notebook = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running in a notebook\n"
                    ]
                }
            ],
            "source": [
                "if not in_notebook:\n",
                "    print(\"Running as script\")\n",
                "    # set up arg parser\n",
                "    parser = argparse.ArgumentParser(description=\"Segment the nuclei of a tiff image\")\n",
                "\n",
                "    parser.add_argument(\n",
                "        \"--patient\",\n",
                "        type=str,\n",
                "        help=\"The patient ID\",\n",
                "    )\n",
                "\n",
                "    parser.add_argument(\n",
                "        \"--well_fov\",\n",
                "        type=str,\n",
                "        help=\"Path to the input directory containing the tiff images\",\n",
                "    )\n",
                "\n",
                "    parser.add_argument(\n",
                "        \"--compartment\",\n",
                "        type=str,\n",
                "        default=\"none\",\n",
                "        help=\"The compartment to segment\",\n",
                "    )\n",
                "\n",
                "    args = parser.parse_args()\n",
                "    well_fov = args.well_fov\n",
                "    compartment = args.compartment\n",
                "    patient = args.patient\n",
                "else:\n",
                "    print(\"Running in a notebook\")\n",
                "    well_fov = \"C2-2\"\n",
                "    compartment = \"organoid\"\n",
                "    patient = \"NF0014\"\n",
                "\n",
                "mask_dir = pathlib.Path(f\"../../data/{patient}/processed_data/{well_fov}\").resolve()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if compartment == \"nuclei\":\n",
                "    mask_path = mask_dir / \"nuclei_masks_reconstructed.tiff\"\n",
                "    mask_output_path = mask_dir / \"nuclei_masks_reconstructed_corrected.tiff\"\n",
                "elif compartment == \"cell\":\n",
                "    mask_path = mask_dir / \"cell_masks_watershed.tiff\"\n",
                "    mask_output_path = mask_dir / \"cell_masks_corrected.tiff\"\n",
                "elif compartment == \"organoid\":\n",
                "    mask_path = mask_dir / \"organoid_masks_reconstructed.tiff\"\n",
                "    mask_output_path = mask_dir / \"organoid_masks_reconstructed_corrected.tiff\"\n",
                "\n",
                "else:\n",
                "    raise ValueError(\"Compartment must be either nuclei, cell or organoid\")\n",
                "\n",
                "mask = tifffile.imread(mask_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Functions for refinement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List, Tuple\n",
                "\n",
                "\n",
                "def calculate_bbox_area(bbox: Tuple[int, int, int, int]) -> int:\n",
                "    \"\"\"\n",
                "    Calculate the area of a bounding box.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    bbox : Tuple[int, int, int, int]\n",
                "        The bounding box coordinates in the format (x_min, y_min, x_max, y_max).\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    int\n",
                "        The area of the bounding box.\n",
                "    \"\"\"\n",
                "    return (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
                "\n",
                "\n",
                "def calculate_overlap(\n",
                "    bbox1: Tuple[int, int, int, int], bbox2: Tuple[int, int, int, int]\n",
                ") -> float:\n",
                "    # calculate the % overlap of the second bbox with the first bbox\n",
                "    if calculate_bbox_area(bbox1) == 0 or calculate_bbox_area(bbox2) == 0:\n",
                "        return 0.0\n",
                "    if calculate_bbox_area(bbox1) >= calculate_bbox_area(bbox2):\n",
                "        x_min = max(bbox1[0], bbox2[0])\n",
                "        y_min = max(bbox1[1], bbox2[1])\n",
                "        x_max = min(bbox1[2], bbox2[2])\n",
                "        y_max = min(bbox1[3], bbox2[3])\n",
                "        overlap_width = max(0, x_max - x_min)\n",
                "        overlap_height = max(0, y_max - y_min)\n",
                "        overlap_area = overlap_width * overlap_height\n",
                "        bbox1_area = calculate_bbox_area(bbox1)\n",
                "        bbox2_area = calculate_bbox_area(bbox2)\n",
                "        overlap_percentage = overlap_area / bbox2_area if bbox2_area > 0 else 0\n",
                "        return overlap_percentage\n",
                "    elif calculate_bbox_area(bbox1) < calculate_bbox_area(bbox2):\n",
                "        x_min = max(bbox1[0], bbox2[0])\n",
                "        y_min = max(bbox1[1], bbox2[1])\n",
                "        x_max = min(bbox1[2], bbox2[2])\n",
                "        y_max = min(bbox1[3], bbox2[3])\n",
                "        overlap_width = max(0, x_max - x_min)\n",
                "        overlap_height = max(0, y_max - y_min)\n",
                "        overlap_area = overlap_width * overlap_height\n",
                "        bbox1_area = calculate_bbox_area(bbox1)\n",
                "        bbox2_area = calculate_bbox_area(bbox2)\n",
                "        overlap_percentage = overlap_area / bbox1_area if bbox1_area > 0 else 0\n",
                "        return overlap_percentage\n",
                "    else:\n",
                "        print(\"Error: Bboxes are the same size\")\n",
                "\n",
                "\n",
                "def merge_sets(list_of_sets: list) -> list:\n",
                "    for i, set1 in enumerate(list_of_sets):\n",
                "        for j, set2 in enumerate(list_of_sets):\n",
                "            if i != j and len(set1.intersection(set2)) > 0:\n",
                "                set1.update(set2)\n",
                "    return list_of_sets\n",
                "\n",
                "\n",
                "def check_for_all_same_labels(\n",
                "    object_information_df: pd.DataFrame,\n",
                ") -> bool:\n",
                "    \"\"\"\n",
                "    Check if all labels in the object information DataFrame are the same.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    object_information_df : pd.DataFrame\n",
                "        The DataFrame containing object information with 'label' column.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    bool\n",
                "        True if all labels are the same, False otherwise.\n",
                "    \"\"\"\n",
                "    return object_information_df[\"label\"].nunique() == 1\n",
                "\n",
                "\n",
                "def missing_slice_check(\n",
                "    object_information_df: pd.DataFrame,\n",
                "    window_min: int = 0,\n",
                "    window_max: int = 2,\n",
                "    interpolated_rows_to_add: List[int] = [],\n",
                "):\n",
                "    max_z = object_information_df[\"z\"].max()\n",
                "    min_z = object_information_df[\"z\"].min()\n",
                "    if max_z - min_z > 1:\n",
                "        if len(object_information_df) < 3:\n",
                "            # get the first row\n",
                "            row = object_information_df.iloc[0]\n",
                "            new_row = {\n",
                "                \"added_z\": row[\"z\"],\n",
                "                \"added_new_label\": row[\"label\"],\n",
                "                \"zslice_to_copy\": row[\"z\"],\n",
                "            }\n",
                "\n",
                "            # interpolate the labels to the middle most slice\n",
                "            # get the middle slice\n",
                "            middle_slice = int((max_z + min_z) / 2)\n",
                "            # insert one slice\n",
                "            z_zlice_to_copy = row[\"z\"]\n",
                "\n",
                "            new_row = {\n",
                "                # 'index': object_information_df['index'].values[0],\n",
                "                # 'index': object_max_slice_label,\n",
                "                \"added_z\": middle_slice,\n",
                "                \"added_new_label\": row[\"label\"],\n",
                "                \"zslice_to_copy\": z_zlice_to_copy,\n",
                "            }\n",
                "            interpolated_rows_to_add.append(pd.DataFrame(new_row, index=[0]))\n",
                "    return interpolated_rows_to_add\n",
                "\n",
                "\n",
                "def add_min_max_boundry_slices(\n",
                "    object_information_df: pd.DataFrame,\n",
                "    global_min_z: int,\n",
                "    global_max_z: int,\n",
                "    interpolated_rows_to_add: List[pd.DataFrame] = [],\n",
                "):\n",
                "    # find labels that are 1 slice away from the min or max and extend the label\n",
                "    for i, row in object_information_df.iterrows():\n",
                "        # check if the z slice is one away from the min or max (global min and max)\n",
                "        if row[\"z\"] == global_max_z - 1:\n",
                "            new_row = {\n",
                "                \"added_z\": global_max_z,\n",
                "                \"added_new_label\": row[\"label\"],\n",
                "                \"zslice_to_copy\": row[\"z\"],\n",
                "            }\n",
                "            interpolated_rows_to_add.append(pd.DataFrame(new_row, index=[0]))\n",
                "        elif row[\"z\"] == global_min_z + 1:\n",
                "            new_row = {\n",
                "                \"added_z\": global_min_z,\n",
                "                \"added_new_label\": row[\"label\"],\n",
                "                \"zslice_to_copy\": row[\"z\"],\n",
                "            }\n",
                "            interpolated_rows_to_add.append(pd.DataFrame(new_row, index=[0]))\n",
                "    return interpolated_rows_to_add\n",
                "\n",
                "\n",
                "def add_masks_where_missing(\n",
                "    new_mask_image: np.ndarray,\n",
                "    interpolated_rows_to_add_df: pd.DataFrame,\n",
                ") -> np.ndarray:\n",
                "    for slice in interpolated_rows_to_add_df[\"added_z\"].unique():\n",
                "        # get the rows that correspond to the slice\n",
                "        tmp_df = interpolated_rows_to_add_df[\n",
                "            interpolated_rows_to_add_df[\"added_z\"] == slice\n",
                "        ]\n",
                "        if tmp_df.shape[0] == 0:\n",
                "            continue\n",
                "        for i, row in tmp_df.iterrows():\n",
                "            # get the z slice to copy mask\n",
                "            new_slice = new_mask_image[row[\"zslice_to_copy\"].astype(int), :, :].copy()\n",
                "            new_slice[new_slice != row[\"added_new_label\"]] = 0\n",
                "\n",
                "            old_slice = new_mask_image[row[\"added_z\"].astype(int), :, :].copy()\n",
                "            max_projected_slice = np.maximum(old_slice, new_slice)\n",
                "            new_mask_image[row[\"added_z\"].astype(int), :, :] = max_projected_slice\n",
                "    return new_mask_image"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Set data flow objects, constants and parameters"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Constants"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "sliding_window_context = 3\n",
                "global_max_z = mask.shape[0]  # number of z slices\n",
                "global_min_z = 0\n",
                "# expand the z slices into a list  of slices between the min and max z slices\n",
                "z_slices = [x for x in range(global_min_z, global_max_z)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Loop through the slices in a sliding window fashion and correct the segmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "new_mask_image = mask.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for z in z_slices[: -(sliding_window_context - 1)]:\n",
                "    interpolated_rows_to_add = []\n",
                "\n",
                "    final_dict = {\n",
                "        \"index1\": [],\n",
                "        \"index2\": [],\n",
                "        \"z1\": [],\n",
                "        \"z2\": [],\n",
                "        \"distance\": [],\n",
                "        \"label1\": [],\n",
                "        \"label2\": [],\n",
                "    }\n",
                "    list_of_cell_masks = []\n",
                "    for z_slice in range(0, new_mask_image.shape[0] - 1):\n",
                "        compartment_df = pd.DataFrame.from_dict(\n",
                "            skimage.measure.regionprops_table(\n",
                "                new_mask_image[z, :, :],\n",
                "                properties=[\"centroid\", \"bbox\"],\n",
                "            )\n",
                "        )\n",
                "        compartment_df[\"z\"] = z_slice\n",
                "\n",
                "        list_of_cell_masks.append(compartment_df)\n",
                "    compartment_df = pd.concat(list_of_cell_masks)\n",
                "\n",
                "    # get the pixel value of the organoid mask at each x,y,z coordinate\n",
                "    compartment_df[\"label\"] = new_mask_image[\n",
                "        compartment_df[\"z\"].astype(int),\n",
                "        compartment_df[\"centroid-0\"].astype(int),\n",
                "        compartment_df[\"centroid-1\"].astype(int),\n",
                "    ]\n",
                "    compartment_df.reset_index(drop=True, inplace=True)\n",
                "    compartment_df[\"new_label\"] = compartment_df[\"label\"]\n",
                "    # drop all labels that are 0\n",
                "    compartment_df = compartment_df[compartment_df[\"label\"] != 0]\n",
                "\n",
                "    # Get the temporary sliding window\n",
                "    tmp_window_df = compartment_df[\n",
                "        (compartment_df[\"z\"] >= z) & (compartment_df[\"z\"] < z + sliding_window_context)\n",
                "    ]\n",
                "\n",
                "    if tmp_window_df[\"z\"].nunique() < sliding_window_context:\n",
                "        continue\n",
                "    for i, row1 in tmp_window_df.iterrows():\n",
                "        for j, row2 in tmp_window_df.iterrows():\n",
                "            if i != j:  # Ensure you're not comparing the same row\n",
                "                if row1[\"z\"] != row2[\"z\"]:\n",
                "                    # get the first bbox\n",
                "\n",
                "                    distance = euclidian_2D_distance(\n",
                "                        (row1[\"centroid-0\"], row1[\"centroid-1\"]),\n",
                "                        (row2[\"centroid-0\"], row2[\"centroid-1\"]),\n",
                "                    )\n",
                "\n",
                "                    if distance < 20:\n",
                "                        final_dict[\"index1\"].append(i)\n",
                "                        final_dict[\"index2\"].append(j)\n",
                "                        final_dict[\"z1\"].append(row1[\"z\"])\n",
                "                        final_dict[\"z2\"].append(row2[\"z\"])\n",
                "                        final_dict[\"distance\"].append(distance)\n",
                "                        final_dict[\"label1\"].append(row1[\"label\"])\n",
                "                        final_dict[\"label2\"].append(row2[\"label\"])\n",
                "    final_df = pd.DataFrame.from_dict(final_dict)\n",
                "    final_df[\"index_set\"] = final_df.apply(\n",
                "        lambda row: frozenset([row[\"index1\"], row[\"index2\"]]), axis=1\n",
                "    )\n",
                "    final_df[\"index_set\"] = final_df[\"index_set\"].apply(lambda x: tuple(sorted(x)))\n",
                "\n",
                "    list_of_sets = final_df[\"index_set\"].tolist()\n",
                "    list_of_sets = [set(s) for s in list_of_sets]\n",
                "    merged_sets = merge_sets(list_of_sets)\n",
                "    # drop the duplicates\n",
                "    merged_sets = list({frozenset(s): s for s in merged_sets}.values())\n",
                "\n",
                "    # from final_df generate the z-ordered cases\n",
                "    for object_set in merged_sets:\n",
                "        # find rows that contain integers that are in the object_set\n",
                "        rows_that_contain_object_set = final_df[\n",
                "            final_df[\"index_set\"].apply(lambda x: set(x).issubset(object_set))\n",
                "        ]\n",
                "        # get the index, label, and z pair\n",
                "        dict_of_object_information = {\"index\": [], \"label\": [], \"z\": []}\n",
                "        for i, row in rows_that_contain_object_set.iterrows():\n",
                "            dict_of_object_information[\"index\"].append(row[\"index1\"])\n",
                "            dict_of_object_information[\"label\"].append(row[\"label1\"])\n",
                "            dict_of_object_information[\"z\"].append(row[\"z1\"])\n",
                "            dict_of_object_information[\"index\"].append(row[\"index2\"])\n",
                "            dict_of_object_information[\"label\"].append(row[\"label2\"])\n",
                "            dict_of_object_information[\"z\"].append(row[\"z2\"])\n",
                "        object_information_df = pd.DataFrame.from_dict(dict_of_object_information)\n",
                "        object_information_df.drop_duplicates(\n",
                "            subset=[\"index\", \"label\", \"z\"], inplace=True\n",
                "        )\n",
                "        object_information_df.sort_values(by=[\"index\", \"z\"], inplace=True)\n",
                "        if check_for_all_same_labels(object_information_df):\n",
                "            # if all labels are the same, skip this object\n",
                "            continue\n",
                "        interpolated_rows_to_add = missing_slice_check(\n",
                "            object_information_df, interpolated_rows_to_add=interpolated_rows_to_add\n",
                "        )\n",
                "        interpolated_rows_to_add = add_min_max_boundry_slices(\n",
                "            object_information_df,\n",
                "            global_min_z=global_min_z,\n",
                "            global_max_z=global_max_z,\n",
                "            interpolated_rows_to_add=interpolated_rows_to_add,\n",
                "        )\n",
                "\n",
                "    if len(interpolated_rows_to_add) == 0:\n",
                "        if z == z_slices[-1]:\n",
                "            tifffile.imwrite(mask_output_path, new_mask_image)\n",
                "        else:\n",
                "            continue\n",
                "    interpolated_rows_to_add_df = pd.concat(interpolated_rows_to_add, axis=0)\n",
                "    new_mask_image = new_mask_image.copy()\n",
                "    new_mask_image = add_masks_where_missing(\n",
                "        new_mask_image=new_mask_image,\n",
                "        interpolated_rows_to_add_df=interpolated_rows_to_add_df,\n",
                "    )\n",
                "\n",
                "    tifffile.imwrite(mask_output_path, new_mask_image)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "GFF_segmentation",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
