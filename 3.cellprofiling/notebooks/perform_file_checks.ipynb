{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "sys.path.append(str(root_dir / \"utils\"))\n",
    "from arg_parsing_utils import check_for_missing_args, parse_args\n",
    "from notebook_init_utils import bandicoot_check, init_notebook\n",
    "\n",
    "root_dir, in_notebook = init_notebook()\n",
    "\n",
    "profile_base_dir = bandicoot_check(\n",
    "    pathlib.Path(\"/home/lippincm/mnt/bandicoot/NF1_organoid_data\").resolve(), root_dir\n",
    ")\n",
    "\n",
    "sys.path.append(f\"{root_dir}/3.cellprofiling/featurization_utils/\")\n",
    "from loading_classes import ImageSetLoader\n",
    "\n",
    "sys.path.append(str(pathlib.Path(f\"{root_dir}/utils\").resolve()))\n",
    "from file_checking import check_number_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = \"NF0014_T1\"\n",
    "well_fov = \"C2-1\"\n",
    "# set path to the processed data dir\n",
    "\n",
    "image_set_path = pathlib.Path(\n",
    "    f\"{profile_base_dir}/data/{patient}/profiling_input_images/{well_fov}/\"  # just to get channels structure\n",
    ")\n",
    "patient_id_file_path = pathlib.Path(f\"{profile_base_dir}/data/patient_IDs.txt\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "rerun_combinations_path = pathlib.Path(\n",
    "    f\"{profile_base_dir}/3.cellprofiling/load_data/rerun_combinations.txt\"\n",
    ").resolve()\n",
    "rerun_combinations_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "patient_ids = pd.read_csv(\n",
    "    patient_id_file_path, header=None, names=[\"patient_id\"]\n",
    ").patient_id.tolist()\n",
    "\n",
    "patient_ids = [patient]  # for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mapping = {\n",
    "    \"DNA\": \"405\",\n",
    "    \"AGP\": \"488\",\n",
    "    \"ER\": \"555\",\n",
    "    \"Mito\": \"640\",\n",
    "    \"BF\": \"TRANS\",\n",
    "    \"Nuclei\": \"nuclei_\",\n",
    "    \"Cell\": \"cell_\",\n",
    "    \"Cytoplasm\": \"cytoplasm_\",\n",
    "    \"Organoid\": \"organoid_\",\n",
    "}\n",
    "image_set_loader = ImageSetLoader(\n",
    "    image_set_path=image_set_path,\n",
    "    anisotropy_spacing=(1, 0.1, 0.1),\n",
    "    channel_mapping=channel_mapping,\n",
    ")\n",
    "\n",
    "channels = image_set_loader.image_names\n",
    "compartments = image_set_loader.compartments\n",
    "channel_combinations = list(itertools.combinations(channels, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each well fov there should be the following number of files:\n",
    "Of course this depends on if both CPU and GPU versions are run, but the CPU version is always run.\n",
    "| Feature Type | No. Compartments | No. Channels | No. Processors | Total No. Files |\n",
    "|--------------|------------------|---------------|----------------|-----------------|\n",
    "| AreaSizeShape | 4 | 1 | 2 | 8 |\n",
    "| Colocalization | 4 | 10 | 2 | 80 |\n",
    "| Granularity | 4 | 5 | 1 | 20 |\n",
    "| Intensity | 4 | 5 | 2 | 40 |\n",
    "| Neighbors | 1 | 1 | 1 | 1 |\n",
    "| Texture | 4 | 5 | 1 | 20 |  \n",
    "\n",
    "Total no. files per well fov = 169\n",
    "\n",
    "### OR\n",
    "For CPU only:\n",
    "For each well fov there should be the following number of files:\n",
    "| Feature Type | No. Compartments | No. Channels | No. Processors | Total No. Files |\n",
    "|--------------|------------------|---------------|----------------|-----------------|\n",
    "| AreaSizeShape | 4 | 1 | 1 | 4 |\n",
    "| Colocalization | 4 | 10 | 1 | 40 |\n",
    "| Granularity | 4 | 5 | 1 | 20 |\n",
    "| Intensity | 4 | 5 | 1 | 20 |\n",
    "| Neighbors | 1 | 1 | 1 | 1 |\n",
    "| Texture | 4 | 5 | 1 | 20 |  \n",
    "\n",
    "Total no. files per well fov = 105\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = [\n",
    "    \"AreaSizeShape\",\n",
    "    \"Colocalization\",\n",
    "    \"Granularity\",\n",
    "    \"Intensity\",\n",
    "    \"Neighbors\",\n",
    "    \"Texture\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_types = [\n",
    "    \"CPU\",\n",
    "    # \"GPU\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = []\n",
    "# construct the file space\n",
    "\n",
    "# area, size, shape\n",
    "for compartment in compartments:\n",
    "    for processor_type in processor_types:\n",
    "        feature_list.append(f\"AreaSizeShape_{compartment}_{processor_type}_features\")\n",
    "# colocalization\n",
    "for channel in channel_combinations:\n",
    "    for compartment in compartments:\n",
    "        for processor_type in processor_types:\n",
    "            feature_list.append(\n",
    "                f\"Colocalization_{compartment}_{channel[0]}.{channel[1]}_{processor_type}_features\"\n",
    "            )\n",
    "# granularity\n",
    "for channel in channels:\n",
    "    for compartment in compartments:\n",
    "        feature_list.append(f\"Granularity_{compartment}_{channel}_CPU_features\")\n",
    "# intensity\n",
    "for channel in channels:\n",
    "    for compartment in compartments:\n",
    "        for processor_type in processor_types:\n",
    "            feature_list.append(\n",
    "                f\"Intensity_{compartment}_{channel}_{processor_type}_features\"\n",
    "            )\n",
    "# neighbors\n",
    "feature_list.append(\"Neighbors_Nuclei_DNA_CPU_features\")\n",
    "# texture\n",
    "for channel in channels:\n",
    "    for compartment in compartments:\n",
    "        feature_list.append(f\"Texture_{compartment}_{channel}_CPU_features\")\n",
    "len(feature_list)  # should be 105 or 169 depending on CPU vs CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurization_rerun_dict = {\n",
    "    \"patient\": [],\n",
    "    \"well_fov\": [],\n",
    "    \"feature\": [],\n",
    "    \"compartment\": [],\n",
    "    \"channel\": [],\n",
    "    \"processor_type\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = 0\n",
    "files_present = 0\n",
    "for patient in patient_ids:\n",
    "    well_fovs = pathlib.Path(\n",
    "        f\"{profile_base_dir}/data/{patient}/zstack_images/\"\n",
    "    ).resolve()\n",
    "\n",
    "    # perform checks for each directory\n",
    "    featurization_data_dirs = list(well_fovs.glob(\"*\"))\n",
    "\n",
    "    for dir in featurization_data_dirs:\n",
    "        if dir.name != \"run_stats\":\n",
    "            dir = pathlib.Path(\n",
    "                f\"{profile_base_dir}/data/{patient}/extracted_features/{dir.name}\"\n",
    "            ).resolve(strict=True)\n",
    "            total_files += len(feature_list)\n",
    "            if not check_number_of_files(dir, len(feature_list)):\n",
    "                # find the missing files\n",
    "                # cross reference the files in the directory\n",
    "                # with the expected feature list\n",
    "                existing_files = [f.stem for f in dir.glob(\"*\") if f.is_file()]\n",
    "\n",
    "                files_present += len(existing_files)\n",
    "                missing_files = set(feature_list) - set(existing_files)\n",
    "                assert len(missing_files) >= 0, \"There should be no missing files\"\n",
    "                assert len(missing_files) <= len(feature_list), (\n",
    "                    f\"There should be at most {len(feature_list)} missing files\"\n",
    "                )\n",
    "                print((len(missing_files) + len(existing_files)), len(feature_list))\n",
    "                assert len(missing_files) + len(existing_files) == len(feature_list), (\n",
    "                    f\"There should be exactly {len(feature_list)} files in the directory\"\n",
    "                )\n",
    "                if missing_files:\n",
    "                    for missing_file in missing_files:\n",
    "                        if missing_file.split(\"_\")[0] == \"Colocalization\":\n",
    "                            featurization_rerun_dict[\"channel\"].append(\n",
    "                                missing_file.split(\"_\")[2].split(\".\")[0]\n",
    "                                + \".\"\n",
    "                                + missing_file.split(\"_\")[2].split(\".\")[1]\n",
    "                            )\n",
    "                            featurization_rerun_dict[\"processor_type\"].append(\n",
    "                                missing_file.split(\"_\")[3]\n",
    "                            )\n",
    "                        elif missing_file.split(\"_\")[0] == \"AreaSizeShape\":\n",
    "                            featurization_rerun_dict[\"channel\"].append(\n",
    "                                \"DNA\"\n",
    "                            )  # AreaSizeShape is always DNA\n",
    "                            featurization_rerun_dict[\"processor_type\"].append(\n",
    "                                missing_file.split(\"_\")[2]\n",
    "                            )\n",
    "                        else:\n",
    "                            featurization_rerun_dict[\"channel\"].append(\n",
    "                                missing_file.split(\"_\")[2]\n",
    "                            )\n",
    "                            featurization_rerun_dict[\"processor_type\"].append(\n",
    "                                missing_file.split(\"_\")[3]\n",
    "                            )\n",
    "                        featurization_rerun_dict[\"patient\"].append(patient)\n",
    "                        featurization_rerun_dict[\"well_fov\"].append(dir.name)\n",
    "                        featurization_rerun_dict[\"feature\"].append(\n",
    "                            missing_file.split(\"_\")[0]\n",
    "                        )\n",
    "                        featurization_rerun_dict[\"compartment\"].append(\n",
    "                            missing_file.split(\"_\")[1]\n",
    "                        )\n",
    "            else:\n",
    "                files_present += len([f.stem for f in dir.glob(\"*\") if f.is_file()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files expected: 10815\n",
      "Total files present: 10815\n",
      "Only 0 files are missing.\n",
      "Percent of files present: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total files expected: {total_files}\")\n",
    "print(f\"Total files present: {files_present}\")\n",
    "print(f\"Only {total_files - files_present} files are missing.\")\n",
    "if total_files == 0:\n",
    "    print(\"No files were expected, so percent present is undefined.\")\n",
    "else:\n",
    "    print(\n",
    "        \"Percent of files present:\", np.round(files_present / total_files * 100, 2), \"%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>well_fov</th>\n",
       "      <th>feature</th>\n",
       "      <th>compartment</th>\n",
       "      <th>channel</th>\n",
       "      <th>processor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [patient, well_fov, feature, compartment, channel, processor_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(featurization_rerun_dict)\n",
    "df.to_csv(rerun_combinations_path, sep=\"\\t\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_fov</th>\n",
       "      <th>feature</th>\n",
       "      <th>compartment</th>\n",
       "      <th>channel</th>\n",
       "      <th>processor_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [well_fov, feature, compartment, channel, processor_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"patient\"]).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GFF_featurization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
