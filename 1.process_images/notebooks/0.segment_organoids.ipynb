{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-12-05 18:25:54.427087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2024-12-05 18:25:55.417156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
                        "2024-12-05 18:25:55.417237: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
                        "2024-12-05 18:25:55.417243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
                    ]
                }
            ],
            "source": [
                "from __future__ import absolute_import, division, print_function, unicode_literals\n",
                "\n",
                "import pathlib\n",
                "import sys\n",
                "\n",
                "import matplotlib\n",
                "import numpy as np\n",
                "\n",
                "matplotlib.rcParams[\"image.interpolation\"] = \"none\"\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "%matplotlib inline\n",
                "%config InlineBackend.figure_format = 'retina'\n",
                "\n",
                "from glob import glob\n",
                "\n",
                "import tifffile\n",
                "from csbdeep.io import save_tiff_imagej_compatible\n",
                "from csbdeep.utils import Path, normalize\n",
                "from stardist import random_label_cmap\n",
                "from stardist.models import StarDist3D\n",
                "from tifffile import imread\n",
                "\n",
                "np.random.seed(6)\n",
                "lbl_cmap = random_label_cmap()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(23, 1537, 1540)\n"
                    ]
                }
            ],
            "source": [
                "# set path to the test image\n",
                "image_file_path = pathlib.Path(\"../../data/z-stack_images/D3-1/D3-1_405.tif\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "\n",
                "nuclei_z_stack = tifffile.imread(image_file_path)\n",
                "print(nuclei_z_stack.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Onmipose"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2024-12-05 18:26:05,315\t[INFO ]\t[core.py    74   _use_gpu_torch    ]\t** TORCH GPU version installed and working. **\n",
                        ">>> GPU activated? 1\n"
                    ]
                }
            ],
            "source": [
                "# Import dependencies\n",
                "import numpy as np\n",
                "from cellpose_omni import core, models\n",
                "\n",
                "# This checks to see if you have set up your GPU properly.\n",
                "# CPU performance is a lot slower, but not a problem if you\n",
                "# are only processing a few images.\n",
                "use_GPU = core.use_gpu()\n",
                "print(\">>> GPU activated? %d\" % use_GPU)\n",
                "\n",
                "# for plotting\n",
                "import matplotlib as mpl\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "mpl.rcParams[\"figure.dpi\"] = 300\n",
                "plt.style.use(\"dark_background\")\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['/home/lippincm/Documents/GFF_3D_organoid_profiling_pipeline/1.process_images/test_dir/D3-1_405.tif']"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import pathlib\n",
                "\n",
                "import omnipose\n",
                "from cellpose_omni import io\n",
                "\n",
                "basedir = pathlib.Path(\"../test_dir/\").resolve(strict=True)\n",
                "files = io.get_image_files(str(basedir))\n",
                "files  # this displays the variable if it the last thing in the code block"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original image shape: (23, 1537, 1540)\n",
                        "data type: uint16\n",
                        "data range: 0 65535\n",
                        "number of images: 1\n"
                    ]
                }
            ],
            "source": [
                "from cellpose_omni import io, transforms\n",
                "from omnipose.utils import normalize99\n",
                "\n",
                "imgs = [io.imread(f) for f in files]\n",
                "\n",
                "# print some info about the images.\n",
                "for i in imgs:\n",
                "    print(\"Original image shape:\", i.shape)\n",
                "    print(\"data type:\", i.dtype)\n",
                "    print(\"data range:\", i.min(), i.max())\n",
                "nimg = len(imgs)\n",
                "print(\"number of images:\", nimg)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2024-12-05 18:26:05,378\t[INFO ]\t[models.py  427  __init__          ]\t>>plant_omni<< model set to be used\n",
                        "2024-12-05 18:26:05,379\t[INFO ]\t[core.py    88   assign_device     ]\t>>>> using CPU\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "resnet_torch.py (308): You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
                    ]
                }
            ],
            "source": [
                "from cellpose_omni import models\n",
                "\n",
                "model_name = \"plant_omni\"\n",
                "\n",
                "dim = 3\n",
                "nclasses = 3  # flow + dist + boundary\n",
                "nchan = 1\n",
                "omni = 1\n",
                "rescale = False\n",
                "diam_mean = 0\n",
                "use_GPU = 0  # Most people do not have enough VRAM to run on GPU... 24GB not enough for this image, need nearly 48GB\n",
                "model = models.CellposeModel(\n",
                "    gpu=use_GPU,\n",
                "    model_type=model_name,\n",
                "    net_avg=False,\n",
                "    diam_mean=diam_mean,\n",
                "    nclasses=nclasses,\n",
                "    dim=dim,\n",
                "    nchan=nchan,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2024-12-05 18:28:44,765\t[INFO ]\t[models.py  427  __init__          ]\t>>plant_omni<< model set to be used\n",
                        "2024-12-05 18:28:44,778\t[INFO ]\t[core.py    74   _use_gpu_torch    ]\t** TORCH GPU version installed and working. **\n",
                        "2024-12-05 18:28:44,779\t[INFO ]\t[core.py    85   assign_device     ]\t>>>> using GPU\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "resnet_torch.py (295): You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
                    ]
                }
            ],
            "source": [
                "from cellpose_omni import models\n",
                "\n",
                "model_name = \"plant_omni\"\n",
                "\n",
                "dim = 3\n",
                "nclasses = 3  # flow + dist + boundary\n",
                "nchan = 1\n",
                "omni = 1\n",
                "rescale = False\n",
                "diam_mean = 0\n",
                "use_GPU = 1  # Most people do not have enough VRAM to run on GPU... 24GB not enough for this image, need nearly 48GB\n",
                "model = models.CellposeModel(\n",
                "    gpu=use_GPU,\n",
                "    model_type=model_name,\n",
                "    net_avg=False,\n",
                "    diam_mean=diam_mean,\n",
                "    nclasses=nclasses,\n",
                "    dim=dim,\n",
                "    nchan=nchan,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2024-12-05 18:28:55,261\t[INFO ]\t[models.py  709  eval              ]\tEvaluating with flow_threshold 0.00, mask_threshold -5.00\n",
                        "2024-12-05 18:28:55,261\t[INFO ]\t[models.py  711  eval              ]\tusing omni model, cluster False\n",
                        "2024-12-05 18:28:55,262\t[INFO ]\t[models.py  1093 eval              ]\tusing dataparallel\n",
                        "2024-12-05 18:28:55,333\t[INFO ]\t[models.py  1104 eval              ]\tshape before transforms.convert_image(): (23, 1537, 1540)\n",
                        "2024-12-05 18:28:55,334\t[INFO ]\t[transforms.py 506  convert_image     ]\tmulti-stack tiff read in as having 23 planes 1 channels\n",
                        "2024-12-05 18:28:55,334\t[INFO ]\t[models.py  1111 eval              ]\tshape after transforms.convert_image(): (23, 1537, 1540, 1)\n",
                        "2024-12-05 18:28:55,334\t[INFO ]\t[models.py  1115 eval              ]\tshape now (1, 23, 1537, 1540, 1)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "conv.py (720): cuDNN cannot be used for large non-batch-splittable convolutions if the V8 API is not enabled or before cuDNN version 9.3+. Consider upgrading cuDNN and/or enabling the V8 API for better efficiency. (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:430.)\n"
                    ]
                },
                {
                    "ename": "OutOfMemoryError",
                    "evalue": "CUDA out of memory. Tried to allocate 14.07 GiB. GPU 0 has a total capacity of 23.55 GiB of which 7.06 GiB is free. Process 754275 has 260.00 MiB memory in use. Including non-PyTorch memory, this process has 15.37 GiB memory in use. Of the allocated memory 15.03 GiB is allocated by PyTorch, and 31.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[11], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# splitting the images into batches helps manage VRAM use so that memory can get properly released\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# here we have just one image, but most people will have several to process\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nimg):\n\u001b[0;32m---> 25\u001b[0m     masks_om[k], flows_om[k], _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet_avg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet_avg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransparency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransparency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflow_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43momni\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momni\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiam_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiam_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflow_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/models.py:1121\u001b[0m, in \u001b[0;36mCellposeModel.eval\u001b[0;34m(self, x, batch_size, indices, channels, channel_axis, z_axis, normalize, invert, rescale, diameter, do_3D, anisotropy, net_avg, augment, tile, tile_overlap, bsize, num_workers, resample, interp, cluster, suppress, boundary_seg, affinity_seg, despur, flow_threshold, mask_threshold, diam_threshold, niter, cellprob_threshold, dist_threshold, flow_factor, compute_masks, min_size, max_size, stitch_threshold, progress, show_progress, omni, calc_trace, verbose, transparency, loop_run, model_loaded, hysteresis)\u001b[0m\n\u001b[1;32m   1118\u001b[0m rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiam_mean \u001b[38;5;241m/\u001b[39m diameter \u001b[38;5;28;01mif\u001b[39;00m (rescale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (diameter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m diameter\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m rescale\n\u001b[1;32m   1119\u001b[0m rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rescale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m rescale\n\u001b[0;32m-> 1121\u001b[0m masks, styles, dP, cellprob, p, bd, tr, affinity, bounds  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_cp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mcompute_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mnet_avg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mtile_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mmask_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mdiam_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiam_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mflow_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mniter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mflow_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mcluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43msuppress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mboundary_seg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboundary_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43maffinity_seg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maffinity_seg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mdespur\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdespur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_3D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43manisotropy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manisotropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mstitch_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstitch_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43momni\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momni\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mcalc_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalc_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;66;03m# the flow list stores: \u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;66;03m# (1) RGB representation of flows\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;66;03m# (2) flow components\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \n\u001b[1;32m   1162\u001b[0m \u001b[38;5;66;03m# 5-8 were added in Omnipose, hence the unusual placement in the list. \u001b[39;00m\n\u001b[1;32m   1163\u001b[0m flows \u001b[38;5;241m=\u001b[39m [plot\u001b[38;5;241m.\u001b[39mdx_to_circ(dP,transparency\u001b[38;5;241m=\u001b[39mtransparency) \n\u001b[1;32m   1164\u001b[0m          \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnclasses\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(cellprob\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m+\u001b[39mtransparency,),np\u001b[38;5;241m.\u001b[39muint8),\n\u001b[1;32m   1165\u001b[0m          dP, cellprob, p, bd, tr, affinity, bounds]\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/models.py:1249\u001b[0m, in \u001b[0;36mCellposeModel._run_cp\u001b[0;34m(self, x, compute_masks, normalize, invert, rescale, net_avg, resample, augment, tile, tile_overlap, bsize, mask_threshold, diam_threshold, flow_threshold, niter, flow_factor, min_size, max_size, interp, cluster, suppress, boundary_seg, affinity_seg, despur, anisotropy, do_3D, stitch_threshold, omni, calc_trace, verbose, pad)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1248\u001b[0m         img \u001b[38;5;241m=\u001b[39m zoom(img,rescale,order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1249\u001b[0m yf, style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_nets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_avg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet_avg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m                           \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtile_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_overlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;66;03m# unpadding \u001b[39;00m\n\u001b[1;32m   1254\u001b[0m yf \u001b[38;5;241m=\u001b[39m yf[unpad\u001b[38;5;241m+\u001b[39m(\u001b[38;5;28mEllipsis\u001b[39m,)]\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/core.py:418\u001b[0m, in \u001b[0;36mUnetModel._run_nets\u001b[0;34m(self, img, net_avg, augment, tile, tile_overlap, bsize, return_conv, progress)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" run network (if more than one, loop over networks and average results\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m net_avg:  \n\u001b[0;32m--> 418\u001b[0m     y, style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_conv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_conv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model)):\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/core.py:520\u001b[0m, in \u001b[0;36mUnetModel._run_net\u001b[0;34m(self, imgs, augment, tile, tile_overlap, bsize, return_conv)\u001b[0m\n\u001b[1;32m    518\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(imgs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;66;03m# at this point imgs is (B,C,*dims)\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     y, style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_conv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_conv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     y, style \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m], style[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    522\u001b[0m style \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (style\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/core.py:366\u001b[0m, in \u001b[0;36mUnetModel.network\u001b[0;34m(self, x, return_conv)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m mkldnn_utils\u001b[38;5;241m.\u001b[39mto_mkldnn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 366\u001b[0m         y, style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     y, style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(X)\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:191\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    193\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/resnet_torch.py:262\u001b[0m, in \u001b[0;36mCPnet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmkldnn:\n\u001b[1;32m    261\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_mkldnn()\n\u001b[0;32m--> 262\u001b[0m T0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# T0 = cp.checkpoint(self.downsample,data) #casues a warning but appears to work, 11 to 8 GB! \u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmkldnn:\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/resnet_torch.py:121\u001b[0m, in \u001b[0;36mdownsample.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 121\u001b[0m     xd\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xd\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/cellpose_omni/resnet_torch.py:74\u001b[0m, in \u001b[0;36mresdown.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 74\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv[\u001b[38;5;241m1\u001b[39m](\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     75\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv[\u001b[38;5;241m3\u001b[39m](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv[\u001b[38;5;241m2\u001b[39m](x))\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/GFF_cellpose/lib/python3.9/site-packages/torch/nn/modules/conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    710\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m     )\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.07 GiB. GPU 0 has a total capacity of 23.55 GiB of which 7.06 GiB is free. Process 754275 has 260.00 MiB memory in use. Including non-PyTorch memory, this process has 15.37 GiB memory in use. Of the allocated memory 15.03 GiB is allocated by PyTorch, and 31.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "torch.cuda.empty_cache()\n",
                "mask_threshold = -5  # usually this is -1\n",
                "flow_threshold = 0.0\n",
                "diam_threshold = 12\n",
                "net_avg = False\n",
                "cluster = False\n",
                "verbose = 1\n",
                "tile = 0\n",
                "chans = None\n",
                "compute_masks = 1\n",
                "resample = False\n",
                "rescale = None\n",
                "omni = True\n",
                "flow_factor = 10  # multiple to increase flow magnitude, useful in 3D\n",
                "transparency = True\n",
                "\n",
                "nimg = len(imgs)\n",
                "masks_om, flows_om = [[]] * nimg, [[]] * nimg\n",
                "\n",
                "# splitting the images into batches helps manage VRAM use so that memory can get properly released\n",
                "# here we have just one image, but most people will have several to process\n",
                "for k in range(nimg):\n",
                "    masks_om[k], flows_om[k], _ = model.eval(\n",
                "        imgs[k],\n",
                "        channels=chans,\n",
                "        rescale=rescale,\n",
                "        mask_threshold=mask_threshold,\n",
                "        net_avg=net_avg,\n",
                "        transparency=transparency,\n",
                "        flow_threshold=flow_threshold,\n",
                "        omni=omni,\n",
                "        resample=resample,\n",
                "        verbose=verbose,\n",
                "        diam_threshold=diam_threshold,\n",
                "        cluster=cluster,\n",
                "        niter=10,\n",
                "        tile=tile,\n",
                "        compute_masks=compute_masks,\n",
                "        flow_factor=flow_factor,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "import ncolor\n",
                "\n",
                "mask = masks_om[0]\n",
                "mask_nc = ncolor.label(mask, max_depth=20)\n",
                "\n",
                "import napari\n",
                "\n",
                "viewer = napari.view_labels(mask_nc)\n",
                "viewer.dims.ndisplay = 3\n",
                "viewer.camera.center = [s // 2 for s in mask.shape]\n",
                "viewer.camera.zoom = 1\n",
                "viewer.camera.angles = (10.90517458968619, -20.777067798396835, 58.04311170773853)\n",
                "viewer.camera.perspective = 0.0\n",
                "viewer.camera.interactive = True\n",
                "\n",
                "img = viewer.screenshot(size=(1000, 1000), scale=1, canvas_only=True, flash=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(3, 3), frameon=False)\n",
                "plt.imshow(img)\n",
                "plt.axis(\"off\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from cellpose_omni import plot\n",
                "from omnipose.plot import apply_ncolor\n",
                "\n",
                "mu = flows_om[0][1]\n",
                "T = flows_om[0][2]\n",
                "bd = flows_om[0][4]\n",
                "# mu.shape,T.shape,bd.shape\n",
                "\n",
                "d = mu.shape[0]\n",
                "\n",
                "from omnipose.utils import rescale\n",
                "\n",
                "c = np.array([1] * 2 + [0] * (d - 2))\n",
                "# c = np.arange(d)\n",
                "\n",
                "\n",
                "def cyclic_perm(a):\n",
                "    n = len(a)\n",
                "    b = [[a[i - j] for i in range(n)] for j in range(n)]\n",
                "    return b\n",
                "\n",
                "\n",
                "slices = []\n",
                "idx = np.arange(d)\n",
                "cmap = mpl.colormaps[\"magma\"]\n",
                "cmap2 = mpl.colormaps[\"viridis\"]\n",
                "\n",
                "for inds in cyclic_perm(c):\n",
                "    slc = tuple([slice(-1) if i else mu.shape[k + 1] // 2 for i, k in zip(inds, idx)])\n",
                "    flow = plot.dx_to_circ(mu[np.where(inds) + slc], transparency=1) / 255\n",
                "    dist = cmap(rescale(T)[slc])\n",
                "    bnds = cmap2(rescale(bd)[slc])\n",
                "    msks = apply_ncolor(masks_om[0][slc])\n",
                "\n",
                "    fig = plt.figure(figsize=[5] * 2, frameon=False)\n",
                "    plt.imshow(np.hstack((flow, dist, bnds, msks)), interpolation=\"none\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from cellpose_omni import core, models\n",
                "\n",
                "# define cellpose model\n",
                "model_name = \"plant_cp\"\n",
                "\n",
                "# this model was trained on 2D slices\n",
                "dim = 2\n",
                "nclasses = 2  # cellpose models have no boundary field, just flow and distance\n",
                "\n",
                "# Cellpose defaults to 2 channels;\n",
                "# this is the setup for grayscale in that case\n",
                "nchan = 2\n",
                "chans = [0, 0]\n",
                "\n",
                "# no rescaling for this model\n",
                "diam_mean = 0\n",
                "\n",
                "\n",
                "use_GPU = core.use_gpu()\n",
                "model = models.CellposeModel(\n",
                "    gpu=use_GPU,\n",
                "    model_type=model_name,\n",
                "    net_avg=False,\n",
                "    diam_mean=diam_mean,\n",
                "    nclasses=nclasses,\n",
                "    dim=dim,\n",
                "    nchan=nchan,\n",
                ")\n",
                "\n",
                "\n",
                "# segmentation parameters\n",
                "omni = 1\n",
                "rescale = False\n",
                "mask_threshold = 0\n",
                "net_avg = 0\n",
                "verbose = 1\n",
                "tile = 0\n",
                "compute_masks = 1\n",
                "rescale = None\n",
                "flow_threshold = 0.0\n",
                "do_3D = True\n",
                "flow_factor = 10\n",
                "\n",
                "masks_cp, flows_cp, _ = model.eval(\n",
                "    imgs,\n",
                "    channels=chans,\n",
                "    rescale=rescale,\n",
                "    mask_threshold=mask_threshold,\n",
                "    net_avg=net_avg,\n",
                "    transparency=True,\n",
                "    flow_threshold=flow_threshold,\n",
                "    verbose=verbose,\n",
                "    tile=tile,\n",
                "    compute_masks=compute_masks,\n",
                "    do_3D=True,\n",
                "    omni=omni,\n",
                "    flow_factor=flow_factor,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "import ncolor\n",
                "\n",
                "mask = masks_cp[0]\n",
                "mask_nc = ncolor.label(mask, max_depth=20)\n",
                "\n",
                "import napari\n",
                "\n",
                "viewer = napari.view_labels(mask_nc)\n",
                "viewer.dims.ndisplay = 3\n",
                "viewer.camera.center = [s // 2 for s in mask.shape]\n",
                "viewer.camera.zoom = 1\n",
                "viewer.camera.angles = (10.90517458968619, -20.777067798396835, 58.04311170773853)\n",
                "viewer.camera.perspective = 0.0\n",
                "viewer.camera.interactive = True\n",
                "\n",
                "img = viewer.screenshot(size=(1000, 1000), scale=1, canvas_only=True, flash=False)\n",
                "plt.figure(figsize=(3, 3), frameon=False)\n",
                "plt.imshow(img)\n",
                "plt.axis(\"off\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cellpose"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from cellpose_omni import core, models\n",
                "from skimage import io\n",
                "from skimage.exposure import rescale_intensity\n",
                "\n",
                "# Clear any previous sessions\n",
                "tf.keras.backend.clear_session()\n",
                "\n",
                "# Load your image data\n",
                "nuclei_z_stack\n",
                "\n",
                "# Check the shape of the array\n",
                "print(nuclei_z_stack.shape)\n",
                "\n",
                "# Normalize the image\n",
                "# Adjust the axis based on the shape of nuclei_z_stack\n",
                "# axis_norm = 0  # or 1, depending on the shape\n",
                "# img = rescale_intensity(nuclei_z_stack, in_range=(1, 99.8), out_range=(0, 1))\n",
                "img = nuclei_z_stack\n",
                "# Initialize the model\n",
                "model_name = \"nuclei\"\n",
                "use_GPU = core.use_gpu()\n",
                "model = models.CellposeModel(gpu=use_GPU, model_type=model_name)\n",
                "\n",
                "# Perform segmentation\n",
                "labels, details, _ = model.eval(img, diameter=50, channels=[0, 0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plot the image and masks\n",
                "fig = plt.figure(figsize=(10, 5))\n",
                "plt.subplot(121)\n",
                "plt.imshow(nuclei_z_stack[8, :, :], cmap=\"gray\")\n",
                "plt.title(\"image\")\n",
                "plt.axis(\"off\")\n",
                "plt.subplot(122)\n",
                "plt.imshow(labels[8], cmap=\"magma\")\n",
                "plt.title(\"masks\")\n",
                "plt.axis(\"off\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# show each z slice of the image and masks\n",
                "for z in range(nuclei_z_stack.shape[0]):\n",
                "    fig = plt.figure(figsize=(10, 5))\n",
                "    plt.subplot(121)\n",
                "    plt.imshow(nuclei_z_stack[z, :, :], cmap=\"gray\")\n",
                "    plt.title(\"image\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.subplot(122)\n",
                "    plt.imshow(labels[z], cmap=\"magma\")\n",
                "    plt.title(\"masks\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "GFF_cellpose",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.21"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
